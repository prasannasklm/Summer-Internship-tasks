{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summer_internship_task2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW4Pg5X1nC8D",
        "outputId": "9495b25d-d472-4171-a8f5-2fccdf2660ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edo4y66LnWbE",
        "outputId": "6d813df5-7f5e-4977-d4bb-eac3e4b323f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Copy of Assignment6.ipynb'\t    numpy.ipynb\n",
            "'Copy of Week-1 Assignment.ipynb'   Pandas.ipynb\n",
            "'Copy of Week-2 Assignment.ipynb'   simplilearn.ipynb\n",
            "'Copy of Week-3 Assignment.ipynb'  'Summer internship TASK-2.ipynb'\n",
            "'Copy of Week-4 Assignment.ipynb'   SUMMER_INTERNSHIP_TASK2.ipynb\n",
            "'Copy of Week-5 Assignment.ipynb'  'SummerInternshipTask(NLP)2.ipynb'\n",
            "'Copy of Week-7 Assignment.ipynb'  'Summer_Intership_Task1 (1).ipynb'\n",
            "'Copy of Week-8 Assignment.ipynb'   Summer_Intership_Task1.ipynb\n",
            " DM.ipynb\t\t\t    Untitled0.ipynb\n",
            " en-te_parallel_corpus.csv\t    Untitled1.ipynb\n",
            " Matplotlib.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_path=\"/content/drive/My Drive/Machine_Translation\""
      ],
      "metadata": {
        "id": "lW2bbZlOndb9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-40tXPpgNsht"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"en-te_parallel_corpus.csv\")\n",
        "english_sentences=df['en_sent']\n",
        "telugu_sentences=df['te_sent']\n"
      ],
      "metadata": {
        "id": "YTQO2rcTQBuj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\"english_sentences\":english_sentences,\"telugu_sentences\":telugu_sentences})\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tm4OPXyFQeG3",
        "outputId": "26a0aa94-2c3d-4de4-8cf0-126a01e43a8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       english_sentences  \\\n",
              "0      Three members of a family were killed in the i...   \n",
              "1      In Monaco-Ville, street signs are printed in b...   \n",
              "2      The same has been confirmed in a report carrie...   \n",
              "3      In this state they can easily survive one year...   \n",
              "4      Annual International Yoga Day is a modern cele...   \n",
              "...                                                  ...   \n",
              "29995  The film has Nayanathara as the primary female...   \n",
              "29996  He carries out this task according to his own ...   \n",
              "29997         The Muslims can have four wives at a time.   \n",
              "29998  After Karnataka High Court's disappointing jud...   \n",
              "29999  Virat Kohli will be resting and Rohit Sharma w...   \n",
              "\n",
              "                                        telugu_sentences  \n",
              "0      ఓకే కుటుంబానికి చెందిన ముగ్గురు మృతిచెందటంతో ఈ...  \n",
              "1      మొనాకో-విల్లెలో, ఫ్రెంచ్, మోనెగస్క్యూ రెండింటి...  \n",
              "2             ప్రముఖ బీబీసీ నివేదిక ఇదే విషయం పేర్కొంది.  \n",
              "3      సంవత్సరానికి అదనంగా ఒక రోజునో లేక ఒక నెలనో చేర...  \n",
              "4      ఇలా అంతర్జాతీయ యోగ దినోత్సవం భారతీయ సంస్కార ప్...  \n",
              "...                                                  ...  \n",
              "29995  ఆ సినిమాలో మొదట నయనతారను హీరోయిన్‌గా ఎంపిక చేయ...  \n",
              "29996  ఆ ప్రతీ సభ్యుడు తన సొంత సామర్థ్యాన్ని బట్టి, త...  \n",
              "29997  తమ మతాచారం ప్రకారం ముస్లింలు ఏకకాలంలో నలుగురు ...  \n",
              "29998  కాగా, జయలలిత బెయిల్ పిటిషన్‌పై కర్ణాటక హైకోర్ట...  \n",
              "29999  రెగ్యులర్ కెప్టెన్ విరాట్ కోహ్లీకి విశ్రాంతి ఇ...  \n",
              "\n",
              "[30000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a328fe99-2147-42ba-aff5-4dc4a551eb48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentences</th>\n",
              "      <th>telugu_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Three members of a family were killed in the i...</td>\n",
              "      <td>ఓకే కుటుంబానికి చెందిన ముగ్గురు మృతిచెందటంతో ఈ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In Monaco-Ville, street signs are printed in b...</td>\n",
              "      <td>మొనాకో-విల్లెలో, ఫ్రెంచ్, మోనెగస్క్యూ రెండింటి...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The same has been confirmed in a report carrie...</td>\n",
              "      <td>ప్రముఖ బీబీసీ నివేదిక ఇదే విషయం పేర్కొంది.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In this state they can easily survive one year...</td>\n",
              "      <td>సంవత్సరానికి అదనంగా ఒక రోజునో లేక ఒక నెలనో చేర...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Annual International Yoga Day is a modern cele...</td>\n",
              "      <td>ఇలా అంతర్జాతీయ యోగ దినోత్సవం భారతీయ సంస్కార ప్...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>The film has Nayanathara as the primary female...</td>\n",
              "      <td>ఆ సినిమాలో మొదట నయనతారను హీరోయిన్‌గా ఎంపిక చేయ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>He carries out this task according to his own ...</td>\n",
              "      <td>ఆ ప్రతీ సభ్యుడు తన సొంత సామర్థ్యాన్ని బట్టి, త...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>The Muslims can have four wives at a time.</td>\n",
              "      <td>తమ మతాచారం ప్రకారం ముస్లింలు ఏకకాలంలో నలుగురు ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>After Karnataka High Court's disappointing jud...</td>\n",
              "      <td>కాగా, జయలలిత బెయిల్ పిటిషన్‌పై కర్ణాటక హైకోర్ట...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>Virat Kohli will be resting and Rohit Sharma w...</td>\n",
              "      <td>రెగ్యులర్ కెప్టెన్ విరాట్ కోహ్లీకి విశ్రాంతి ఇ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a328fe99-2147-42ba-aff5-4dc4a551eb48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a328fe99-2147-42ba-aff5-4dc4a551eb48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a328fe99-2147-42ba-aff5-4dc4a551eb48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean english sentances\n",
        "def clean_eng(text):\n",
        "    # Lowercase all characters\n",
        "    text = text.lower()\n",
        "    # Remove quotes\n",
        "    text = re.sub(\"'\", '', text)\n",
        "    # Remove all the special characters\n",
        "    exclude = set(string.punctuation) # Set of all special characters\n",
        "    text = ''.join([c for c in text if c not in exclude])\n",
        "    # Remove all numbers from text\n",
        "    remove_digits = str.maketrans('', '', digits)\n",
        "    text = text.translate(remove_digits)\n",
        "    # Remove extra spaces\n",
        "    text= text.strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "xI0id65sQkgK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean telugu sentances\n",
        "def clean_tel(text):\n",
        "    # Lowercase all characters\n",
        "    text = text.lower()\n",
        "    # Remove quotes\n",
        "    text = re.sub(\"'\", '', text)\n",
        "    # Remove all the special characters\n",
        "    exclude = set(string.punctuation) # Set of all special characters\n",
        "    text = ''.join([c for c in text if c not in exclude])\n",
        "    # Remove all numbers from text\n",
        "    remove_digits = str.maketrans('', '', digits)\n",
        "    text = text.translate(remove_digits)\n",
        "    # Remove Telugu numbers from text\n",
        "    text = re.sub(\"[౦౧౨౩౪౫౬౭౮౯]\", '', text)\n",
        "    # Remove extra spaces\n",
        "    text= text.strip()\n",
        "    text = '<s>'+ text + '</s>'\n",
        "    return text"
      ],
      "metadata": {
        "id": "_UjSVXXQeyhw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean text\n",
        "data_df = data.copy()\n",
        "data_df[\"english_sentences\"] = data_df[\"english_sentences\"] .apply(lambda x: clean_eng(x))\n",
        "data_df[\"telugu_sentences\"] = data_df[\"telugu_sentences\"] .apply(lambda x: clean_tel(x))"
      ],
      "metadata": {
        "id": "gqBYAwDxe9ST"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary of English\n",
        "all_eng_words=set()\n",
        "for eng in data_df.english_sentences:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)"
      ],
      "metadata": {
        "id": "xlNPs1GZfCia"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary of French \n",
        "all_telugu_words=set()\n",
        "for tel in data_df.telugu_sentences:\n",
        "    for word in tel.split():\n",
        "        if word not in all_telugu_words:\n",
        "            all_telugu_words.add(word)"
      ],
      "metadata": {
        "id": "t7lUeRkUgr2i"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Max Length of source sequence\n",
        "lenght_list=[]\n",
        "for l in data_df.english_sentences:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_src = np.max(lenght_list)\n",
        "max_length_src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZUOTzBdg6js",
        "outputId": "e8b28c5e-c2f3-43a2-a2db-2373b73ee555"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Max Length of target sequence\n",
        "lenght_list=[]\n",
        "for l in data_df.telugu_sentences:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_tar = np.max(lenght_list)\n",
        "max_length_tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xpkNoqlg9N8",
        "outputId": "80abc6ce-d485-48c0-eb62-2eaf7299f822"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "184"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_telugu_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_telugu_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3y0gx0HhJI4",
        "outputId": "79e17f48-21b3-4e9d-c215-b14958842fd1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24819, 68082)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_decoder_tokens += 1 # For zero padding\n",
        "num_decoder_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_csZOsUhO9z",
        "outputId": "83d0c8ee-6e7a-4994-f0fb-d2915bc13852"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68083"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "metadata": {
        "id": "BRtqG0jPh0Ip"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "metadata": {
        "id": "Smjq21kkh0vW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = shuffle(data_df)\n",
        "data_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "QMkAqd7siGsf",
        "outputId": "4393ad37-ae7c-4491-b79c-266609d1185b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       english_sentences  \\\n",
              "28779  sejal sharma has committed suicide and tv indu...   \n",
              "26830  the other five have been identified and would ...   \n",
              "714    indian security forces gave a befitting reply ...   \n",
              "18561  the devotees believe that the nandi idol in fr...   \n",
              "10042             bumrah is an absolutely quality bowler   \n",
              "12928  i have come here to offer my respect to venera...   \n",
              "7714     india thus took a  lead in the fivematch series   \n",
              "5453   bihar chief minister nitish kumar and rjd pres...   \n",
              "19951  the  seats where the elections will be held ar...   \n",
              "15682        the watch pairs with an iphone  or iphone s   \n",
              "\n",
              "                                        telugu_sentences  \n",
              "28779  <s>ప్రముఖ హిందీ బుల్లితెర నటి సెజల్ శర్మ ఆత్మహ...  \n",
              "26830  <s>మరో ఐదుగురు పరారీలో ఉన్నారని వారిని కూడా త్...  \n",
              "714    <s>భారత భద్రతా అధికారులు కూడా పాక్‌ బృందాల కాల...  \n",
              "18561  <s>ఈ ఆలయంలో ఉన్న పెద్ద నందీశ్వరుడి విగ్రహం అంత...  \n",
              "10042                     <s>బుమ్రా అద్భుతమైన బౌలర్‌</s>  \n",
              "12928  <s>నేను ఇక్కడకు వచ్చింది కఠోర శ్రమజీవి అయిన గౌ...  \n",
              "7714   <s>దీంతో ఐదు మ్యాచ్‌ల సిరీస్‌లో భారత్  ఆధిక్యం...  \n",
              "5453   <s>ఆయన ఇక్కడ ముఖ్యమంత్రి నితీష్‌కుమార్‌ను ఆర్‌...  \n",
              "19951  <s>దక్షిణ  పరగణాలు దక్షిణ కోలకతా హుగ్లి జిల్లా...  \n",
              "15682  <s>ఐఫోన్ ఇంకా ఐఫోన్ ఎస్ స్మార్ట్‌ఫోన్‌లను ఈ వా...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18bdf44d-dc38-4fc7-8bc8-262f13eef188\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentences</th>\n",
              "      <th>telugu_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28779</th>\n",
              "      <td>sejal sharma has committed suicide and tv indu...</td>\n",
              "      <td>&lt;s&gt;ప్రముఖ హిందీ బుల్లితెర నటి సెజల్ శర్మ ఆత్మహ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26830</th>\n",
              "      <td>the other five have been identified and would ...</td>\n",
              "      <td>&lt;s&gt;మరో ఐదుగురు పరారీలో ఉన్నారని వారిని కూడా త్...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>indian security forces gave a befitting reply ...</td>\n",
              "      <td>&lt;s&gt;భారత భద్రతా అధికారులు కూడా పాక్‌ బృందాల కాల...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18561</th>\n",
              "      <td>the devotees believe that the nandi idol in fr...</td>\n",
              "      <td>&lt;s&gt;ఈ ఆలయంలో ఉన్న పెద్ద నందీశ్వరుడి విగ్రహం అంత...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10042</th>\n",
              "      <td>bumrah is an absolutely quality bowler</td>\n",
              "      <td>&lt;s&gt;బుమ్రా అద్భుతమైన బౌలర్‌&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12928</th>\n",
              "      <td>i have come here to offer my respect to venera...</td>\n",
              "      <td>&lt;s&gt;నేను ఇక్కడకు వచ్చింది కఠోర శ్రమజీవి అయిన గౌ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7714</th>\n",
              "      <td>india thus took a  lead in the fivematch series</td>\n",
              "      <td>&lt;s&gt;దీంతో ఐదు మ్యాచ్‌ల సిరీస్‌లో భారత్  ఆధిక్యం...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5453</th>\n",
              "      <td>bihar chief minister nitish kumar and rjd pres...</td>\n",
              "      <td>&lt;s&gt;ఆయన ఇక్కడ ముఖ్యమంత్రి నితీష్‌కుమార్‌ను ఆర్‌...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19951</th>\n",
              "      <td>the  seats where the elections will be held ar...</td>\n",
              "      <td>&lt;s&gt;దక్షిణ  పరగణాలు దక్షిణ కోలకతా హుగ్లి జిల్లా...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15682</th>\n",
              "      <td>the watch pairs with an iphone  or iphone s</td>\n",
              "      <td>&lt;s&gt;ఐఫోన్ ఇంకా ఐఫోన్ ఎస్ స్మార్ట్‌ఫోన్‌లను ఈ వా...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18bdf44d-dc38-4fc7-8bc8-262f13eef188')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18bdf44d-dc38-4fc7-8bc8-262f13eef188 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18bdf44d-dc38-4fc7-8bc8-262f13eef188');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train - Test Split\n",
        "X, y = data_df.english_sentences, data_df.telugu_sentences\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjZdOle-ieKt",
        "outputId": "29e19f00-68d9-4da0-c9a6-f1992e5a6eca"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27000,), (3000,))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.to_pickle(project_path+'X_train.pkl')\n",
        "X_test.to_pickle(project_path+'X_test.pkl')"
      ],
      "metadata": {
        "id": "wsacL9TeoKj9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "metadata": {
        "id": "2t-1w56tijG2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoder - Decoder Model Architecture"
      ],
      "metadata": {
        "id": "JzZPPyVRixty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 50"
      ],
      "metadata": {
        "id": "AEnmQEyVi4jq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "jYpVC12mi9oJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "id": "rVuRbyLEjAl_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "lkRKXUCpjE_U"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "train_samples_steps = len(X_train) // batch_size\n",
        "val_samples_steps = len(X_test) // batch_size"
      ],
      "metadata": {
        "id": "81HFNYl9jJzn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate train and test datra\n",
        "train_gen = generate_batch(X_train, y_train, batch_size = batch_size)\n",
        "test_gen = generate_batch(X_test, y_test, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "nKIoYqsojOIU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a helper function to save the model after each epoch \n",
        "# in which the loss decreases \n",
        "filepath = project_path+'NMT_model_enc_dec.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "# Defining a helper function to reduce the learning rate each time \n",
        "# the learning plateaus \n",
        "reduce_alpha = ReduceLROnPlateau(monitor ='val_loss', factor = 0.2,patience = 1, min_lr = 0.001)\n",
        "# stop traning if there increase in loss\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "callbacks = [checkpoint, es, reduce_alpha] "
      ],
      "metadata": {
        "id": "Ohcanx59jRbp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model.fit_generator(generator = train_gen,steps_per_epoch = train_samples_steps,epochs=epochs,validation_data = test_gen,validation_steps = val_samples_steps,callbacks = callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBYom6NxjVQj",
        "outputId": "b0f6e9f5-2f0e-47f0-f4e4-a5fc037284e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Setup"
      ],
      "metadata": {
        "id": "lvAiFVXUs_NS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "metadata": {
        "id": "KyjHXAowoTDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decode Sample Sequences"
      ],
      "metadata": {
        "id": "LSD5cOWvtJ8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "vd2GkUdHtIr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on Train Dataset"
      ],
      "metadata": {
        "id": "nmNL810MtkTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
        "for k in range(10):\n",
        "    (input_seq, actual_output), _ = next(test_gen)\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('Input English sentence:', X_test[k:k+1].values[0])\n",
        "    print('Actual Telugu Translation:', y_test[k:k+1].values[0][6:-4])\n",
        "    print('Predicted Telugu Translation:', decoded_sentence[:-4])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "XbFgcS1ftW1Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}